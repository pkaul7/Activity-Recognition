# -*- coding: utf-8 -*-
"""CS-7641_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uIr8Ob3tWzpL-nN6puRPURZo2r-UP_Yv
"""
import os
import unsupervisedlearning as ul
import supervisedlearning as sl
import pandas as pd
from sklearn import model_selection
import numpy as np
from numpy import pi
from matplotlib.colors import rgb2hex
from matplotlib.cm import get_cmap
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn import svm
from sklearn.metrics import confusion_matrix
import itertools

import warnings
warnings.filterwarnings("ignore")
path = 'output_plots'
if not os.path.exists(path):
    os.makedirs(path)

def plot_variance(S, n_components=10):

    S_sq = S*S
    S_sum = np.sum(S_sq)
    recovered_var = []
    for i in range(1,n_components+1):
        S_i = np.sum(S_sq[:i])
        curr = S_i/S_sum
        recovered_var.append(curr)
    return recovered_var

def main():
	import matplotlib.pyplot as plt
	# Load datasets
	train = pd.read_csv('train.csv')
	test = pd.read_csv('test.csv')
	X = train.iloc[:, 0:-2]
	X_data= np.array(X)

	train['Data'] = 'Train'

	label = train.pop('Activity')
	print("Plotting TSNE plot for activities...")
	# Create datasets
	t_data = train.copy()
	d_data = t_data.pop('Data')
	s_data = t_data.pop('subject')

	label_counts = label.value_counts()
	scl = StandardScaler()
	t_data = scl.fit_transform(t_data)

	pca = PCA(n_components=0.9, random_state=3)
	pca_data = pca.fit(t_data)
	t_data = pca.fit_transform(t_data)


	tsne = TSNE(random_state=3)
	transformed_t = tsne.fit_transform(t_data)

	fig, plot_y = plt.subplots(1, 1, figsize=(14,6))

	colors = ['k','b','g','c','m','y']

	for i, group in enumerate(label_counts.index):
	    t = (label==group).values
	    plot_y.scatter(x=transformed_t[t][:,0], y=transformed_t[t][:,1], c=colors[i], alpha=0.5, label=group)
	plot_y.set_title('TSNE - Distribution of activity')
	plot_y.set_xlabel('tsne 1')
	plot_y.set_ylabel('tsne 2')

	plt.savefig("output_plots/Tsne_Activity.png" , format = 'png', bbox_inches = 'tight')
	plt.clf()

	n = s_data.unique().shape[0]
	cm = get_cmap('gist_rainbow')
	c_list = []
	for k in np.arange (0,1.01,1/(n-1)):
	  c_list.append(k)
	  
	clr = [rgb2hex(cm(t)) for t in c_list]

	fig, plot_y = plt.subplots(1, 1, figsize=(14,6))

	for i, group in enumerate(s_data.unique()):
	    m = (s_data==group).values
	    plot_y.scatter(x=transformed_t[m][:,0], y=transformed_t[m][:,1], label=group , alpha=0.5 , c=clr[i])

	plot_y.set_title('TSNE - Distribution of Participant ')
	plot_y.set_xlabel('tsne 1')
	plot_y.set_ylabel('tsne 2')

	plt.savefig("output_plots/Tsne_Participant.png" , format = 'png', bbox_inches = 'tight')
	plt.clf()

	print("Plotting Variance captured by PCA components...")
	U,S,V = ul.pca(X_data)
	r_var = plot_variance(S)
	x_axis = np.arange(10)+1
	plt.plot(x_axis,r_var, 'b', linewidth=2)
	plt.xlabel('Number of components')
	plt.ylabel('Variance Ratio')
	plt.savefig("output_plots/Variance_plot.png" , format = 'png', bbox_inches = 'tight')
	plt.clf()



	# Create plots
	complete_df = pd.concat([train, test], axis=0)
	X_train, X_val, y_train, y_val = model_selection.train_test_split(train.iloc[:, 0:-2], train.iloc[:, -1:], test_size=0.1, random_state = 0)
	X_test, y_test = test.iloc[:, 0:-2], test.iloc[:, -1:]

	#Number of instances for each activity
	scores_test,scores_train,svc = sl.getScores()
	plt.bar(label_counts.index, label_counts, color=['yellow', 'red', 'green', 'blue', 'cyan', 'purple'])
	plt.xticks(label_counts.index, rotation=45)
	plt.savefig("output_plots/Activity_Barplot.png" , format = 'png', bbox_inches = 'tight')
	plt.clf()

	#Testing scores for each algorithm
	algorithms = ["Logistic Regression", "Linear SVM", "Decision Tree", "Naive Bayes", "Random Forest"]
	ax = plt.subplot(111)
	x=np.arange(len(algorithms))
	ax.bar(x-0.2, scores_train, width=0.2, color='b', align='center', label='Train Data')
	ax.bar(x, scores_test, width=0.2, color='g', align='center', label='Test Data')
	plt.legend()
	ax.set_ylabel('Score')
	ax.set_xlabel('Algorithms')
	ax.set_xticks(x)
	ax.set_xticklabels(algorithms)
	ax.set_xlim(-1,7)
	plt.savefig("output_plots/Accuracy_Scores.png" , format = 'png', bbox_inches = 'tight')
	plt.clf()

	#Comparing importance of Gyro sensor and Accelarometer Sensor

	# Get importances
	features = complete_df.columns
	importances = svc.coef_.ravel()
	Gyro_score = 0
	Acc_score = 0
	for importance, feature in zip(importances, features):
	    if 'Gyro' in feature and importance>0:
	        Gyro_score += importance
	    if 'Acc' in feature and importance>0:
	        Acc_score += importance

	x = [Gyro_score, Acc_score]
	y = ["Gyroscope", "Accelerometer"]
	fig, ax = plt.subplots()
	y_pos = np.arange(len(y))
	ax.barh(y_pos, x)
	ax.set_yticks(y_pos)
	ax.set_yticklabels(y)
	ax.invert_yaxis() 
	ax.set_xlabel('Importance')
	ax.set_ylabel('Sensor Type')
	ax.set_title('Sensor Importance')
	plt.savefig("output_plots/Sensor_Importance.png" , format = 'png', bbox_inches = 'tight')
	plt.clf()
	
	cf_mat = confusion_matrix(y_test.values.ravel(), svc.predict(X_test))
	plt.imshow(cf_mat, interpolation='nearest', cmap=plt.cm.Blues)
	plt.title("Confusion Matrix")
	plt.colorbar()
	fmt = 'd'
	thresh = cf_mat.max()/2.
	for i, j in itertools.product(range(cf_mat.shape[0]), range(cf_mat.shape[1])):
	        plt.text(j, i, format(cf_mat[i, j], fmt),
	                 horizontalalignment="center",
	                 color="white" if cf_mat[i, j] > thresh else "black")
	tick_marks= np.arange(len(label_counts))
	plt.xticks(tick_marks, label_counts.index, rotation=45)
	plt.yticks(tick_marks, label_counts.index)
	plt.ylabel('True label')
	plt.xlabel('Predicted label')
	plt.tight_layout()
	plt.savefig("output_plots/confusion_matrix.png" , format = 'png', bbox_inches = 'tight')
	plt.clf()

if __name__ == "__main__":
  main()